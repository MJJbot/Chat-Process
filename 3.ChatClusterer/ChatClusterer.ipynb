{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "import codecs\n",
    "import time\n",
    "from SentenceSim import sentence_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num = 700\n",
    "data_size = 5000\n",
    "algorithm = \"past\"\n",
    "past_threshold = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "filename = \"../../Data/1to100_chat_norm3.txt\" #input(\"filename: \")\n",
    "with open(filename, 'r', encoding='utf-8-sig') as data_file:\n",
    "    chats = data_file.readlines()\n",
    "    chats = list(map(lambda chat: chat.strip(), chats)) # to delete newline character\n",
    "print(len(chats))\n",
    "print(\"time: %.3f secs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "sim_matrix = sentence_sim(chats[:data_size])\n",
    "print(\"time: %.3f secs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if algorithm == \"hc\":\n",
    "    clusterer = AgglomerativeClustering(n_clusters=cluster_num, affinity='precomputed', linkage='average').fit(1 - sim_matrix)\n",
    "    clusters = [[] for _ in range(cluster_num)]\n",
    "    label_list = clusterer.labels_\n",
    "    for idx in range(len(label_list)):\n",
    "        clusters[label_list[idx]].append(idx)\n",
    "elif algorithm == \"past\":\n",
    "    clusters = []\n",
    "    idx_x, idx_y = np.where(sim_matrix > past_threshold)\n",
    "    for idx in range(len(idx_x)):\n",
    "        x, y = idx_x[idx], idx_y[idx]\n",
    "        if y <= x:\n",
    "            continue\n",
    "        cluster_exist = False\n",
    "        for cluster_idx in range(len(clusters)):\n",
    "            if x in clusters[cluster_idx]:\n",
    "                cluster_exist = True\n",
    "                clusters[cluster_idx].add(y)\n",
    "                break\n",
    "        if cluster_exist == False:\n",
    "            cluster = {x, y}\n",
    "            clusters.append(cluster)\n",
    "\n",
    "cluster_lens = list()\n",
    "for idx in range(len(clusters)):\n",
    "    cluster_lens.append((len(clusters[idx]), idx))\n",
    "cluster_lens.sort(reverse=True)\n",
    "print(\"time: %.3f secs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(f\"{algorithm}_{len(clusters)}_{data_size}({chunk_num}).txt\", 'w', encoding='utf-8') as output_file:\n",
    "    for len, idx in cluster_lens:\n",
    "        if len == 1:\n",
    "            continue\n",
    "        output_file.write(\"---------------------------------------\\n\")\n",
    "        for chat in clusters[idx]:\n",
    "            output_file.write(chats[chat] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.92\n",
    "\n",
    "start_time = time.time()\n",
    "close_chats = np.where(sim_matrix > similarity_threshold)\n",
    "relate_counts = [[0, idx] for idx in range(data_size)]\n",
    "for idx in range(len(close_chats[0])):\n",
    "    relate_counts[close_chats[0][idx]][0] += 1\n",
    "relate_counts.sort(reverse=True)\n",
    "print(relate_counts[:30])\n",
    "print(\"time: %.3f secs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(30):\n",
    "    print(chats[relate_counts[idx][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
